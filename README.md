## **66DaysOfData**

## Introduction

The #66DaysOfDataScience is a  challenge/Initiative by @Ken_Jee, A data scientist,  designed to help you create great data science learning habits. Along with the habits, you will be joining an incredible community where you can learn alongside and work with other like-minded people!

The challenge is simple, it only has two parts.
- Learn data science every day for 66 days straight. You should learn for minimum of 5 minutes per day.
- Share your progress on your social media platform of choice using #66DaysOfData

This has 3 benefits : 
- You create a habit of daily learning 
- You get used to sharing your work, something that can help you create many opportunities for yourself. 
- The community holds you accountable. This is often the missing piece for many people looking to learn new skills.<br/>


I will record the daily progress here for upcoming 66 days including today ! . Also I will share progress on my [Linkedin](https://www.linkedin.com/in/kumar-mahendra/) . I am very Excited for the Journey :wink: 

### Day 1 
<br/>-----------------------------------------------------------------------------------------------------------------<br/>

Today I started by brushing up basic python programming skills and start learning two freuenctly used libraries in python which are,
- **NumPy** : A powerful scientific computing library
- **Pandas**: A library used for data manipulation and analysis 

*If needed ,You can see the required Jupyter notebooks that I used for learning these. I got these during my internship at **VERZEO**.Links are:-*
- [python introduction](https://github.com/kumar-mahendra/66DaysOfData/blob/main/1_Introduction_to_python.ipynb)
- [pandas library](https://github.com/kumar-mahendra/66DaysOfData/blob/main/2_Pandas_Library.ipynb)
- [numpy library](https://github.com/kumar-mahendra/66DaysOfData/blob/main/3_Intro_to_Numpy.ipynb)

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 2 

Today I did two things : 
- Attended the discussion session-1 on the topic "Probability theory and probabilistic Models" which was conducted by one of our senior Abhishek Varghese, where I learned a new concept, the Sigma field, and also learned about probabilistic models. It was fun.

- Also, started reading the book "AI and Machine Learning for Coders" by Laurence Moroney. I read the first chapter which was all about an introduction to TensorFlow.
I also wrote my first code( [link](https://github.com/kumar-mahendra/66DaysOfData/blob/main/single_neuron.ipynb)) which is simple sequential one 
neuron model to find relationship between two variables made with help of keras API of tensorflow.

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 3

Continued reading the book "AI and ML for Coders"
- Finished chapter-2 i.e. "Introduction to Computer Vision". I learned how to make a very basic computer vision neural network([code](https://github.com/kumar-mahendra/66DaysOfData/blob/main/simple_multi_neuron.ipynb)) using the clothing dataset -Fashion MNIST. but it was a somewhat limited model as data use only monochromic images and each image contains only one cloth type. In reality, images are mostly colorful and contain more than one object. This problem can be solved using techniques like convolutions that can help us to extract features of images, which I will continue tomorrow.

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 4 

Today I learned a few more interesting concepts which are:

- Convolution ( or filtering ) and pooling ( a way to reduce the size of an image while retaining features of images),
- Also learned about a technique -"Dropout regularization", which is useful to avoid overfitting of convolutional neural networks.

Parallelly, applied those techniques to build two simple models that can distinguish between dogs vs cats, horse vs human.

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 5

Today I haven't read book. I realised I have to also see mathematics behind some algorithms and before that It is required to have sound foundation of basic probability and statistics concepts. So I revised notes of probability and statistics using [this notebook.](https://github.com/kumar-mahendra/66DaysOfData/blob/main/4_Probability%20%20and_Statistics%20.ipynb)

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 6 

Bunk Day!!
Given day I enjoyed our college's (IIT GOA)  very first Technical Fest "Cepeus" . I participated in all events I could like CTFs, Competitive Programming etc.
Wached a TED talk by Fei Fei li, A Computer Vision Expert on [Youtube](https://www.youtube.com/watch?v=40riCqvRoMs)

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 7 

Today I started next chapter "Tensorflow-Datasets" in "ML and AI for coders".Get introduced to tensorflow-datasets.
Also came to know about a very interesting data vizualization library, `bokeh` . Solved Tutorial 1 & 2 from their git-hub repository.

`Good News` :I made my first contribution on `bokeh` tutorials I was solving.Feels good!!

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 8 

`Good news` : My application on Coursera for Financial Aid for "Data Scientists Toolbox" gets approved.:fire::fire:

Completed Week 1 on above mentioned specialization . To know more about this click [here](https://www.coursera.org/learn/data-scientists-tools).

Summary of Week 1:
- What is data and data Science? Some cool projects in data science (examples)
- Process of a data Science project :
  - Asking a Question which need answer 
  - Finding relevent data
  - Data Cleaning and Explore the data
  - Draw Conclusion 
  - Lastly, publish/share results through medium of blogs/article etc. 
  

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 9 

Completed Week 2 & started Week 3 in "Data Scientists Toolbox" .
Summary of what I learnt :
- Introduction to R and R Studio , getting familirialize with IDE i.e RStudio and get to know about R Packages
- Version Control System like Git and How to use GitHub
 
<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 10 

:star: Today was a day of full-fillment . Successfully completed "Data Scientists Toolbox" course . :smiley: :smiley: 

Summarizing Todays Learning : 
- Linked GitHub to RStudio and learned how to commit and push to Repository and pull from repository etc. etc. 
- Last Part was quite interesting , Get to know about how to design a experiment/setup your project , difference between various types of data analysis techniques and when to use them and when not. 
- Finally course ended with an introduction to Big Data and Why it is Buzz nowdays . Challenges and Advantages to Big Data .

`Next Target` : Apply for next course in Data Science Specialization. <br/>

From next day I will resume reading my book "AI and Machine learning for Coders". Planning to soon start a interesting project....search in progress.:eyes: :eyes:


<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 11 

Today I have practice all remaining  `bokeh` Tutorials( at least tried) [here](https://github.com/bokeh/bokeh-notebooks/tree/main/tutorial). Honestly, these tutorials involved Javascript and Web development at some places so I ignored them completely :sweat_smile: :sweat_smile: 

>KeyTakeAway -  Leaned something that can help me make my future projects looks attractive :sunglasses:

`future aspect` : Will get back to it after I will learn JavaScript.
<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 12 

Today I did a small EDA project on `blood-pressure` dataset just for fun . Here I made a interactive plot using bokeh-library I learned . It was a fun experience. 
project code and demostration is present [here](https://github.com/kumar-mahendra/66DaysOfData/blob/main/EDA_Blood_Pressure.ipynb).

<br/>-----------------------------------------------------------------------------------------------------------------<br/>


### Day 13 

Today I learned some new things. Continued reading the book `AI and ML for Coders` by laurance moroney. Here I finished chapter 4 and 5. 
In chapter 4 , he mostly talked about tensorflow_datasets and how to use them effectively (Confession- I don't enjoy that much but just have a look ) at the end of chapter there some interesting stuff came up. Explored ETL process i.e. *Extract , Transform and Load* and here he talked about how optimization of CPU and GPU happen.

Then I started my next chapter i.e. `Introduction to Natural language processing`. It is much more interesting. In this chapter I learned following concepts : `tokenization`, `cleaning_text` using various technique like stopword removal etc. and also used  BeautifulSoap , a tool to clean HTML files and extract important info from that ignoring syntaxes!! Cool....ðŸ˜ŽðŸ˜Ž

At the end , I did applied the skills gained to clean  `IMDb dataset` of movie_reviews([link](https://colab.research.google.com/drive/1Q-EeoMKf4CYQD6m1FJv6ZGz0uMthBNG8#scrollTo=4jO0ExFcRNTL)). That's all for today . Overall I did much more than by previous days.

Tomorrow will dive a little more deeper into `NLP` in next chapter. 

<br/>-----------------------------------------------------------------------------------------------------------------<br/>


### Day 14 
Today I finished next chapter "Making sentiment programmable using embeddings". It is quite a confusing topic but exciting ! Till now We have not design any method to give meaning to words , Embedding is one such way which help us to set up a relative meaning to various words . Two words are similar if vectors associated with them are nearly pointing in same direction. But this vectors formation requires some work . I read theory but I think It require some more time to understand it completely. For now I have learnt how to use embedding in tensorflow and also  `make a model` that could predict whether a news headline is *sarcastic* or *non-sarcastic* . It is not that perfect but not overfitting thats something I liked !! . Will work on this model more to increase validation accuracy. You can find the model [here](https://github.com/kumar-mahendra/66DaysOfData/blob/main/Natural_Language_Processing.ipynb) . 

`Info` : If you want to tweak hyper-parameters , you can do that by simply passing hyperparameters in a function , I have kept model flexible so everyone can use it even without understanding whole process. 

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 15 

From today our next semester(Sem-IV) of college has started . very first day we had 5 classes so didn't get much time to practice. learnt an algorithm  "Naive Gaussian Elimination" method to solve linear system of equations . Wrote down a python code to automate the same. you can find code [here](https://github.com/kumar-mahendra/Mathematics_of_Scientific_Computing/blob/main/Linear_systems/Naive_Gauss_method.ipynb)

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 16

Today I continued learning a little more about NLP . learnt a few things like
- Using regularization techniques i.e. lasso and ridge regularization in model which may increase accracy of model
- Using pretrained models of text embeddings available on tensorflow-hub

**Tech-Info** : `Embedding projector` is an online tool by tensorflow which you can use to vizualize embeddings

<br/>-----------------------------------------------------------------------------------------------------------------<br/>






