## **66DaysOfData**

## Introduction

The #66DaysOfDataScience is a  challenge/Initiative by @Ken_Jee, A data scientist,  designed to help you create great data science learning habits. Along with the habits, you will be joining an incredible community where you can learn alongside and work with other like-minded people!

The challenge is simple, it only has two parts.
- Learn data science every day for 66 days straight. You should learn for minimum of 5 minutes per day.
- Share your progress on your social media platform of choice using #66DaysOfData

This has 3 benefits : 
- You create a habit of daily learning 
- You get used to sharing your work, something that can help you create many opportunities for yourself. 
- The community holds you accountable. This is often the missing piece for many people looking to learn new skills.<br/>


I will record the daily progress here for upcoming 66 days including today ! . Also I will share progress on my [Linkedin](https://www.linkedin.com/in/kumar-mahendra/) . I am very Excited for the Journey :wink: 

### Day 1 
<br/>-----------------------------------------------------------------------------------------------------------------<br/>

Today I started by brushing up basic python programming skills and start learning two freuenctly used libraries in python which are,
- **NumPy** : A powerful scientific computing library
- **Pandas**: A library used for data manipulation and analysis 

*If needed ,You can see the required Jupyter notebooks that I used for learning these. I got these during my internship at **VERZEO**.Links are:-*
- [python introduction](https://github.com/kumar-mahendra/66DaysOfData/blob/main/1_Introduction_to_python.ipynb)
- [pandas library](https://github.com/kumar-mahendra/66DaysOfData/blob/main/2_Pandas_Library.ipynb)
- [numpy library](https://github.com/kumar-mahendra/66DaysOfData/blob/main/3_Intro_to_Numpy.ipynb)

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 2 

Today I did two things : 
- Attended the discussion session-1 on the topic "Probability theory and probabilistic Models" which was conducted by one of our senior Abhishek Varghese, where I learned a new concept, the Sigma field, and also learned about probabilistic models. It was fun.

- Also, started reading the book "AI and Machine Learning for Coders" by Laurence Moroney. I read the first chapter which was all about an introduction to TensorFlow.
I also wrote my first code( [link](https://github.com/kumar-mahendra/66DaysOfData/blob/main/single_neuron.ipynb)) which is simple sequential one 
neuron model to find relationship between two variables made with help of keras API of tensorflow.

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 3

Continued reading the book "AI and ML for Coders"
- Finished chapter-2 i.e. "Introduction to Computer Vision". I learned how to make a very basic computer vision neural network([code](https://github.com/kumar-mahendra/66DaysOfData/blob/main/simple_multi_neuron.ipynb)) using the clothing dataset -Fashion MNIST. but it was a somewhat limited model as data use only monochromic images and each image contains only one cloth type. In reality, images are mostly colorful and contain more than one object. This problem can be solved using techniques like convolutions that can help us to extract features of images, which I will continue tomorrow.

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 4 

Today I learned a few more interesting concepts which are:

- Convolution ( or filtering ) and pooling ( a way to reduce the size of an image while retaining features of images),
- Also learned about a technique -"Dropout regularization", which is useful to avoid overfitting of convolutional neural networks.

Parallelly, applied those techniques to build two simple models that can distinguish between dogs vs cats, horse vs human.

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 5

Today I haven't read book. I realised I have to also see mathematics behind some algorithms and before that It is required to have sound foundation of basic probability and statistics concepts. So I revised notes of probability and statistics using [this notebook.](https://github.com/kumar-mahendra/66DaysOfData/blob/main/4_Probability%20%20and_Statistics%20.ipynb)

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 6 

Bunk Day!!
Given day I enjoyed our college's (IIT GOA)  very first Technical Fest "Cepeus" . I participated in all events I could like CTFs, Competitive Programming etc.
Wached a TED talk by Fei Fei li, A Computer Vision Expert on [Youtube](https://www.youtube.com/watch?v=40riCqvRoMs)

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 7 

Today I started next chapter "Tensorflow-Datasets" in "ML and AI for coders".Get introduced to tensorflow-datasets.
Also came to know about a very interesting data vizualization library, `bokeh` . Solved Tutorial 1 & 2 from their git-hub repository.

`Good News` :I made my first contribution on `bokeh` tutorials I was solving.Feels good!!

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 8 

`Good news` : My application on Coursera for Financial Aid for "Data Scientists Toolbox" gets approved.:fire::fire:

Completed Week 1 on above mentioned specialization . To know more about this click [here](https://www.coursera.org/learn/data-scientists-tools).

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

### Day 9 


<br/>-----------------------------------------------------------------------------------------------------------------<br/>

