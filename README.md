## **66DaysOfData**
[`day 1`](#day-1) [`day 2`](#day-2) [`day 3`](#day-3) [`day 4`](#day-4)[`day 5`](#day-5)[`day 20`](#day-20)

## Introduction

The #66DaysOfDataScience is a  challenge/Initiative by  Mr. Ken_Jee, A data scientist,  started to help you create great data science learning habits. Along with the habits, you will be joining an incredible community where you can learn alongside and work with other like-minded people!

The challenge is simple, it only has two parts.
- Learn data science every day for 66 days straight. You should learn for minimum of 5 minutes per day.
- Share your progress on your social media platform of choice using #66DaysOfData

This has 3 benefits : 
- You create a habit of daily learning 
- You get used to sharing your work, something that can help you create many opportunities for yourself. 
- The community holds you accountable. This is often the missing piece for many people looking to learn new skills.<br/>


I will record the daily progress here for upcoming 66 days including today ! . Also I will share progress on my [Linkedin](https://www.linkedin.com/in/kumar-mahendra/) . I am very Excited for the Journey :wink: 

#### `Day 1` 
<br/>-----------------------------------------------------------------------------------------------------------------<br/>

 I started by brushing up basic python programming skills and start learning these libraries in python,
- **NumPy** : A powerful scientific computing library
- **Pandas**: A library used for data manipulation and analysis 

  **REFERENCES**
- [python introduction](https://github.com/kumar-mahendra/66DaysOfData/blob/main/1_Introduction_to_python.ipynb)
- [pandas library](https://github.com/kumar-mahendra/66DaysOfData/blob/main/2_Pandas_Library.ipynb)
- [numpy library](https://github.com/kumar-mahendra/66DaysOfData/blob/main/3_Intro_to_Numpy.ipynb)

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 2` 
 
- Attended the discussion session-1 on the topic "Probability theory and probabilistic Models" which was conducted by one of our senior Abhishek Varghese, where I learned a new concept, `the Sigma field`, and also learned about probabilistic models.

- Also, started reading the book `AI and Machine Learning for Coders` by `Laurence Moroney`. I read the 1st chapter which was about an `introduction to TensorFlow`.
- Written code for  a simple ['one neuron model'](https://github.com/kumar-mahendra/66DaysOfData/blob/main/single_neuron.ipynb)

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 3`

- Read 2nd chapter  "Introduction to Computer Vision". Made basic [CV neural network](https://github.com/kumar-mahendra/66DaysOfData/blob/main/simple_multi_neuron.ipynb) 
- Dataset Used - `Fashion MNIST` 

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 4` 

- Started 3rd chapter . learned about filtering technique `convolution` and dimension reduction technique `pooling`.
- get to know about `Dropout regularization`, an attempt to avoid overfitting of CNN (sometimes :confuse:).

 finally applied these techniques to classify `dogs vs cats` images [NLP](https://github.com/kumar-mahendra/66DaysOfData/blob/main/Natural_Language_Processing.ipynb)

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 5`

- Gave book some rest. Revised [`probability and statistics`](https://github.com/kumar-mahendra/66DaysOfData/blob/main/4_Probability%20%20and_Statistics%20.ipynb) conepts.

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 6` 

- participated in `CTF` contest conducted during Tech-Fest `Cepheus` of our college. 
- Watched [TED talk](https://www.youtube.com/watch?v=40riCqvRoMs) by Ms. `Fei Fei li`, A computer vision expert.

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 7` 

- Started 4th chapter `Tensorflow-Datasets`. Just read introdiuction part.
- Get to know about a  data vizualization library, `bokeh` . Solved Tutorial 1 & 2 from their git-hub [repository](https://github.com/bokeh/bokeh-notebooks/tree/main/tutorial).
- `Good News` :I made my first contribution on `bokeh` tutorials I was solving.

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 8` 

`Good news` : My application on Coursera for Financial Aid for [`Data Scientists Toolbox`](https://www.coursera.org/learn/data-scientists-tools) gets approved.:fire::fire:

- completed Week 1 of this specialization .

_Summary of Week 1_:
- What is data and data Science? Some cool projects in data science (examples)
- Process of a data Science project :
  - Asking a Question which need answer 
  - Finding relevent data
  - Data Cleaning and Explore the data
  - Draw Conclusion 
  - Lastly, publish/share results through medium of blogs/article etc. 
  

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 9` 

- Completed Week 2 & started Week 3 in "Data Scientists Toolbox" .

_Summary of Week 2 & 3_ :
- Introduction to R and R Studio , getting familirialize with IDE i.e RStudio and get to know about R Packages
- Version Control System like Git and How to use GitHub
 
<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 10` 

:star: Successfully completed "Data Scientists Toolbox" course . :smiley: :smiley: 

_Summarizing Todays Learning_ : 
- Linked GitHub to RStudio and learned how to commit and push to Repository and pull from repository etc. etc. 
- Last Part was quite interesting , Get to know about how to design a experiment/setup your project , difference between various types of data analysis techniques and when to use them and when not. 
- Finally course ended with an introduction to Big Data and Why it is Buzz nowdays . Challenges and Advantages to Big Data .

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 11` 

Today I have practice all remaining  `bokeh` Tutorials( at least tried) [here](https://github.com/bokeh/bokeh-notebooks/tree/main/tutorial). Honestly, these tutorials involved Javascript and Web development at some places so I ignored them completely :sweat_smile: :sweat_smile: 

>KeyTakeAway -  Leaned something that can help me make my future projects looks attractive :sunglasses:
<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 12` 

- Today I did a small EDA practice on `blood-pressure` dataset just for fun . Here I made a interactive plot using bokeh-library I learned . 
- code for the same is [here](https://github.com/kumar-mahendra/66DaysOfData/blob/main/EDA_Blood_Pressure.ipynb).

<br/>-----------------------------------------------------------------------------------------------------------------<br/>


#### `Day 13` 

- Finished readling chapter 4 along with next chapter `Introdcution to NLP`.
- Topics convered : Using TFDS, ETL(extract, tranform & load) process, How optimization of CPU and GPU happen
- NLP conepts convered : tokenization, cleaning_text, **BeautifulSoap**
- practiced NLP concepts learned on 'IMDb dataset'.[code](https://colab.research.google.com/drive/1Q-EeoMKf4CYQD6m1FJv6ZGz0uMthBNG8#scrollTo=4jO0ExFcRNTL)).
- That's It for today :sweaty_smile:!!

<br/>-----------------------------------------------------------------------------------------------------------------<br/>


#### `Day 14` 
- Read chapter 6 `Making sentiment programmable using embeddings`.
- Embeddings give relative meaning to words using concept of vectors. Embedded words vectors with similar meaning points in nearly same direction !
- Made a model [`news headline prediction : sarcastic or not`](https://github.com/kumar-mahendra/66DaysOfData/blob/main/Natural_Language_Processing.ipynb) . 
 to check tone of news headline. validation acurracy ~ 80%
`Info` : If you want to tweak hyper-parameters , you can do that by simply passing hyperparameters in a function , I have kept model flexible so everyone can use it even without understanding whole process. 

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 15` 

- Winter breaks ends. Next semester begins.
-learnt and coded `Navie Gauss Elimination` method for solving linear system of equations. [code link](https://github.com/kumar-mahendra/Mathematics_of_Scientific_Computing/blob/main/Linear_systems/Naive_Gauss_method.ipynb)

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 16`

- NLP - Finisted chapter 6 . Topics covered : Using regularization techniques (lasso and ridge regularization) in model which may increase accracy of model, Using pretrained models of text embeddings available on tensorflow-hub

**Tech-Info** : `Embedding projector` is an online tool by tensorflow which you can use to vizualize embeddings

<br/>-----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 17` 

- Read chapter 7 `Recurrent neural networks(RNN)`
- RNN give meaning to order in which words appear. Example- LSTM (long-short term memory), a bidirectional RNN 
- Can be used even if inputs are not of same shapes.<br/>
- Read a `Cristopher Olah`'s [blog on LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/).<br/>
- Attended [`Jack Raifer Barukh`'s](https://www.linkedin.com/in/jackraifer/) talk on `Road to data science`.<br/>
   `Key Takeaway` <br/> 
 - Data scientist role is yet not clear to companies as they even don't know what they looking for in data scientist. So try out every single interview you can and get experience as much as you can.
 - Keep models simple and once you start something first finish it then experiment with it ...else you will never complete the project.
 - Do projects that ultimately are helpful and will be used.

<br/>-----------------------------------------------------------------------------------------------------------------<br/>


#### `Day 18` 

- Explored a  little bit dart language. Didn't get excited so leave that.
- NLP concepts learnt : use pre-trained RNNs (particulary GloVe) to train the model.

<br/>----------------------------------------------------------------------------------------------------------------<br/>


#### `Day 19` 

- Just did some revision !! Mostly did academic related work. 

<br/>----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 20` 

- Worte algorithms for sorting technqiues - mergesort (tried to improve efficiency) and quicksort(using random pivot).

<br/>----------------------------------------------------------------------------------------------------------------<br/>

#### `Day 21`

- Read about Statistic concept(s) : t-stat,z-stat,F-stat

<br/>--------------------------------------------------------------------------------------------------------------<br/>


